{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d4b8299d",
      "metadata": {
        "id": "d4b8299d"
      },
      "outputs": [],
      "source": [
        "#import libraries\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import transforms, datasets\n",
        "from torchsummary import summary\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d12441c",
      "metadata": {
        "id": "7d12441c"
      },
      "outputs": [],
      "source": [
        "#define the model class deriving from PyTorch’s on.Module. \n",
        "#This approach is like TensorFlow’s model subclassing. \n",
        "#Here, you defined the class name NeuralNetwork. \n",
        "#This class contains two elements:\n",
        "#The __init__ method, which acts like the class constructor. You use this method to define the feedforward network. \n",
        "#Specifically, you flatten the input (reshape the image from (28, 28) to a 728-dimensional vector. \n",
        "#Then, you create the linear stack of layers. \n",
        "#It has the same structure as the network created with TensorFlow. \n",
        "#There are, of course, slight differences in naming conventions. You use Linear (PyTorch) instead of Dense (TensorFlow). \n",
        "#In PyTorch, you must use activation functions separately, right after the Linear layers.\n",
        "#The forward method takes the input image, flattens it, and then passes it through the network to calculate the prediction (score array).\n",
        "\n",
        "class_names = range(10);\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 64),            \n",
        "            nn.Tanh(),            \n",
        "            nn.Dropout(.2),\n",
        "            \n",
        "            nn.Linear(64, 128),\n",
        "            nn.Sigmoid(),\n",
        "            nn.Dropout(.2),\n",
        "\n",
        "            nn.Linear(128, len(class_names)),\n",
        "            nn.Softmax(dim=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_stack(x)\n",
        "        return logits\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aa10f042",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa10f042",
        "outputId": "358a9575-b0ad-42bf-8e66-ec4e84c7feaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "           Flatten-1                  [-1, 784]               0\n",
            "            Linear-2                   [-1, 64]          50,240\n",
            "              Tanh-3                   [-1, 64]               0\n",
            "           Dropout-4                   [-1, 64]               0\n",
            "            Linear-5                  [-1, 128]           8,320\n",
            "           Sigmoid-6                  [-1, 128]               0\n",
            "           Dropout-7                  [-1, 128]               0\n",
            "            Linear-8                   [-1, 10]           1,290\n",
            "           Softmax-9                   [-1, 10]               0\n",
            "================================================================\n",
            "Total params: 59,850\n",
            "Trainable params: 59,850\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.01\n",
            "Params size (MB): 0.23\n",
            "Estimated Total Size (MB): 0.24\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "#initialize the model and display its summary:\n",
        "model = NeuralNetwork();\n",
        "\n",
        "summary(model, (1, 28, 28))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5bf51ad1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bf51ad1",
        "outputId": "48654835-ffd6-4014-e176-2011f0fe84c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 115981329.61it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 52011890.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 35281740.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 2765354.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#load data\n",
        "\n",
        "#When accessing the dataset, you can specify the transformations to apply to each item. \n",
        "#Here, you use ToTensor transform, which converts MNIST images to tensors and scales the images to the range 0-1.\n",
        "#To load the data, you use the DataLoader utility class. \n",
        "#This class enables you to load multiple images at once. \n",
        "#You control the number of images to load using the batch_size parameter. \n",
        "#You set its value to 32, the same as TensorFlow’s default value for the fit method.\n",
        "\n",
        "\n",
        "# Training data \n",
        "training_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transforms.ToTensor()\n",
        ")\n",
        "\n",
        "# Test data\n",
        "test_data = datasets.MNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=transforms.ToTensor()\n",
        ")\n",
        "\n",
        "# Dataloaders \n",
        "batch_size = 32\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fae80e7",
      "metadata": {
        "id": "0fae80e7"
      },
      "outputs": [],
      "source": [
        "#specify the loss function, and the optimizer\n",
        "#Similar to tensorflow, you use the CrossEntropyLoss, and use the Adam optimizer. \n",
        "#For the learning rate, you set 1e-3, which is the same value as the default in TensorFlow.\n",
        "\n",
        "learning_rate = 1e-3;\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7dccfea6",
      "metadata": {
        "id": "7dccfea6"
      },
      "outputs": [],
      "source": [
        "#Then, you must define the method for training and evaluating your feedforward neural network. \n",
        "#This is equivalent to the fit method from TensorFlow.\n",
        "\n",
        "#The first method, train_loop, uses the backpropagation algorithm to optimize the trainable parameters \n",
        "#to minimize the prediction error of the neural network. \n",
        "#The second method, test_loop, calculates the neural network \n",
        "#error using the test images and displays the accuracy and loss value. \n",
        "\n",
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, (x, y) in enumerate(dataloader):\n",
        "        # Compute prediction and loss\n",
        "        pred = model(x)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "def test_loop(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in dataloader:\n",
        "            pred = model(x)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    \n",
        "    print(f\"Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07ade6c1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07ade6c1",
        "outputId": "cc6ab6eb-8c31-442c-d225-e8129d97e5e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1:\n",
            "Accuracy: 91.5%, Avg loss: 1.555247 \n",
            "\n",
            "Epoch 2:\n",
            "Accuracy: 93.1%, Avg loss: 1.533483 \n",
            "\n",
            "Epoch 3:\n",
            "Accuracy: 93.5%, Avg loss: 1.530424 \n",
            "\n",
            "Epoch 4:\n",
            "Accuracy: 94.4%, Avg loss: 1.519677 \n",
            "\n",
            "Epoch 5:\n",
            "Accuracy: 94.5%, Avg loss: 1.518376 \n",
            "\n",
            "Epoch 6:\n",
            "Accuracy: 95.0%, Avg loss: 1.513600 \n",
            "\n",
            "Epoch 7:\n",
            "Accuracy: 95.0%, Avg loss: 1.512689 \n",
            "\n",
            "Epoch 8:\n",
            "Accuracy: 94.8%, Avg loss: 1.514118 \n",
            "\n",
            "Epoch 9:\n",
            "Accuracy: 95.3%, Avg loss: 1.510094 \n",
            "\n",
            "Epoch 10:\n",
            "Accuracy: 94.9%, Avg loss: 1.514308 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "#now invoke those methods to train and evaluate the model. Like TensorFlow, you use ten epochs:\n",
        "#model gives 95% accuracy\n",
        "\n",
        "epochs = 10\n",
        "\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}:\")\n",
        "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
        "    test_loop(test_dataloader, model, loss_fn)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the test images with their labels:\n",
        "test_images, test_labels = next(iter(test_dataloader))\n",
        "\n",
        "# Recognize digits\n",
        "prediction_result = model(test_images);\n",
        "\n",
        "# Get predicted labels\n",
        "predicted_labels = prediction_result.argmax(1);"
      ],
      "metadata": {
        "id": "pF5EjPYO2S0-"
      },
      "id": "pF5EjPYO2S0-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get randomly selected image for preview\n",
        "preview_image_index = np.random.randint(0, test_images.shape[0] - 1)\n",
        "\n",
        "plt.figure()\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.grid(False)\n",
        "plt.imshow(test_images[preview_image_index][0].numpy(), cmap=plt.cm.binary)\n",
        "\n",
        "plt.xlabel(f\"Actual: {test_labels[preview_image_index]} \\n Predicted: {predicted_labels[preview_image_index]}\", fontsize=20);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "ZgIV2fPL2S6C",
        "outputId": "e506bc38-1434-431f-adc7-a238cb4445a3"
      },
      "id": "ZgIV2fPL2S6C",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}